\documentclass{article}
\usepackage{graphicx} % Required for inserting images
%  USE PACKAGES  ---------------------- 
\usepackage[margin=0.7in,vmargin=1in]{geometry}
\usepackage{amsmath,amsthm,amsfonts}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{float}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{hyperref,color}
\usepackage{enumitem,amssymb}
\newlist{todolist}{itemize}{4}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}%
\hspace{-2.5pt}}
\newcommand{\HREF}[2]{\href{#1}{#2}}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{tabularx}
\usepackage{longtable}
\lstset{
basicstyle=\small\ttfamily,
% columns=flexible,
upquote=true,
breaklines=true,
showstringspaces=false
}
%  -------------------------------------------- 

%  HEADER AND FOOTER (DO NOT EDIT) ----------------------
\newcommand{\problemnumber}{0}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[L]{\textbf{Question \problemnumber}}
\newcommand{\newquestion}[1]{
\clearpage % page break and flush floats
\renewcommand{\problemnumber}{\#1} % set problem number for header
\phantom{}  % Put something on the page so it shows
}
\fancyfoot[L]{IE 332}
\fancyfoot[C]{Project \#2 Report}
\fancyfoot[R]{Page \thepage}
\renewcommand{\footrulewidth}{0.4pt}

%  --------------------------------------------


%  COVER SHEET (FILL IN THE TABLE AS INSTRUCTED IN THE ASSIGNMENT) ----------------------
\newcommand{\addcoversheet}{
\clearpage
\thispagestyle{empty}
\vspace*{0.5in}

\begin{center}
\Huge{{\bf IE 332 Project \#2}} % <-- replace with correct assignment #

Due: April 28th, 11:59pm EST % <-- replace with correct due date and time
\end{center}

\vspace{0.3in}

\noindent We have {\bf read and understood the assignment instructions}. We certify that the submitted work does not violate any academic misconduct rules, and that it is solely our own work. By listing our names below we acknowledge that any misconduct will result in appropriate consequences. 

\vspace{0.2in}

\noindent {\em ``As a Boilermaker pursuing academic excellence, I pledge to be honest and true in all that I do.
Accountable together -- we are Purdue.''}

\vspace{0.3in}

\begin{table}[h!]
  \begin{center}
    \label{tab:table1}
    \begin{tabular}{c|ccccc|c|c}
      Student & Sub-Alg & Main Alg & Testing & Report & X & X & X\\
      \hline
     Talya Arpaci & 20 & 20 & 10 & 10 & 10 & 100 & 0\\
      Hershi Meher & 20 & 10 & 50 & 10 & 10 & 110 & +10\\
      Mohamed Abuelreish & 20 & 20 & 10 & 20 & 10 & 70 & -30\\
      Andrew Newquist & 30 & 30 & 10 & 20 & 60 & 150 & +50\\
      Nicholas Alfano & 10 & 10 & 20 & 10 & 10 & 60 & -40\\
      \hline
      St Dev & 11.73 & 13.69 & 7.31 & 6.12 & 4.69 & 9.30 & 9.30\\
    \end{tabular}
  \end{center}
\end{table}

\vspace{0.2in}

\noindent Date: \today.
}
%  -----------------------------------------

%  TODO LIST (COMPLETE THE FULL CHECKLIST - USE AS EXAMPLE THE FIRST CHECKED BOXES!) ----------------------
\newcommand{\addtodo}{
\clearpage
\thispagestyle{empty}

\section*{Read Carefully. Important!}

\noindent By electronically uploading this assignment to Brightspace you acknowledge these statements and accept any repercussions if in any violation of ANY Purdue Academic Misconduct policies. You must upload your homework on time for it to be graded. No late assignments will be accepted. {\bf Only the last uploaded version of your assignment before the due date will be graded}.

\vspace{0.2in}

\noindent {\bf NOTE:} You should aim to submit no later than 30 minutes before the deadline, as there could be last minute network traffic that would cause your assignment to be late, resulting in a grade of zero. 

\vspace{0.2in}

\noindent When submitting your assignment it is assumed that every student considers the below checklist, as there are grading consequences otherwise (e.g., not submitting a cover sheet is an automatic grade of ZERO).

\begin{todolist}

    \item Your solutions were prepared using the \LaTeX template provided in Brightspace. 
    \item Your submission has a cover sheet as its first page and this checklist as its second page, according to the template provided.
	 \item All of your solutions (program code, etc.) are included in the submission as requested. % Check this checkbox and the following ones if satisfied <---
    \item You have not included any screen shots, photos, etc. (plots should be intermediately saved as .png files and then added into your .tex file). % <---
	 \item  All math notation and algorithms (algorithmic environment) are created using appropriate \LaTeX code (no pictures, handwritten solutions, etc.). % <---
    \item  The .pdf is submitted as an individual file and not in a {\tt .zip}.
    \item You kept the \LaTeX source code in your files until this assignment is graded, in case you are required to show proof of creating your assignment using \LaTeX.  % <---
    \item If submitting with a partner, your partner is added in the submission section in Gradescope after you upload your file. % <---
    \item You have correctly matched each question to its page \# in the .pdf submission in the Gradescope section (after you uploaded your file).
    \item  Watch videos on creating pseudocode if you need a refresher or quick reference to the idea. These are good starter videos:    % <---
    
     \HREF{https://www.youtube.com/watch?v=4jLO0vXPktU}{www.youtube.com/watch?v=4jLO0vXPktU} 
    
    \HREF{https://www.youtube.com/watch?v=yGvfltxHKUU}{www.youtube.com/watch?v=yGvfltxHKUU}
\end{todolist}
}

%% LaTeX
% Für alle, die die Schönheit von Wissenschaft anderen zeigen wollen
% For anyone who wants to show the beauty of science to others

%  -----------------------------------------
\begin{document}

\addcoversheet
\addtodo

\fancyhead[L]{\textbf{Table of Contents}}
\newpage
\tableofcontents

\newpage
\fancyhead[L]{\textbf{Executive Summary}}
\section{Executive Summary}
\subsection{Introduction}
Image classification is the process of extracting classes of information from a multi–channel bitmap image. The raster obtained as a result of image classification can be used to create thematic maps. Depending on the nature of the analyst's interaction with the computer during the classification process, there are two types of image classification: classification with training and classification without training.\newline

\noindent When classifying images with training, spectral signatures obtained from training samples are used. Using the image classification toolbar, you can easily create training samples corresponding to the extracted classes. It can also easily create a signature file from training samples, which will then be used by multidimensional classification tools to classify the image.\newline

\noindent This project aims to demonstrate limitations of image classification technology using 5 algorithms for fooling an image classifier. Using adversarial attacks, we are manipulating input images to fool this classifier and show that even the most complex systems could be easily deceived. The results of this project could be used to reveal weak points in the existing systems and to contribute to the development of reliable image classifiers. With our project we are going to use a trained classification model.\newline



\subsection{Project Statement}
 Our team was given a pre-trained model that is able to classify an image as either a dandelion or a grass. The project's aim is to fool the classifier to think that a dandelion is most probably a grass and that a grass is most probably a dandelion. We have to achieve this by making 5 machine learning and/or optimization  algorithms that in the end are to be put within a parent algorithm that works by a majority classifier to assign a budget, the amount of pixels to be changed  within an image within a sub-algorithm. The sum of these budgets should not exceed 1\% of total pixels within an image. The format of the output is a list of two probabilities of an image being classified as a dandelion and a grass, the sum of which equate to a total of 1  which is a 100\% and the final status of an image which are: grass, not\_grass, dandelion, not\_dandelion, where ``not\_" prefixes mean that the image has been successfully fooled.

\subsection{Navigation of the Group's GitHub Organization}
Link to access  \href{https://github.com/IE-332-Project-2-Group}{GitHub Organization}.
\newline
\newline
The group established an organization in GitHub named "IE-332-Project-2-Group". This organization consists of 16 Repositories, 10 of which are relevant to Project 2 (The others for Assignment 2). Those 10 Repositories follow the naming scheme of PROJECT-XXXXXX. The XXXXXX is the content contained within the repository. It must be noted that more than 5 sub-algorithms were in development for this project in the case of one failing. The number associated with said sub-algorithms are not accurate to the number in the report. The name of said sub-algorithms is however accurate. When navigating the GitHub, these names should be used to find the respective repository of what was included in the main algorithm.
\fancyhead[L]{\textbf{Algorithm Development}}
\section{Algorithm  Development}
\subsection{Introduction}
The first step in creating an algorithm that we have taken is understanding the project outcomes. We tried to clearly define what our algorithms should do. This important step has helped us to not only create the right algorithms, but also make sure that they have reached their maximized optimal efficiency.\newline

\noindent Once we have got an understanding of the task, we have started developing a plan. The plan included all stages of solving the project, as well as determining how we would evaluate the effectiveness of the sub-algorithms as well as the parent algorithm.\newline

\noindent Furthermore, the amount of time it takes to execute the algorithm is important for the efficiency of the algorithms. For this project we have determined the time required to execute the algorithm should not exceed 10 seconds.\newline

\noindent Once there was a developed a plan and defined the time, we started researching different existing machine learning and optimization articles to find the best suitable ones for this project. Our group has decided to give each person an algorithm to work on. Nevertheless, some members of our team wanted to work on more than one algorithm. Those could be found within \newline

\noindent Having developed all of the algorithm our team started working on the budget assignment algorithm \%describe algorithm\% and parent algorithm where all 5 sub-algorithms are combined with an assigned budget to alternately manipulate an image.\newline

\noindent While coding for our algorithms we have faced many challenges but the biggest one that easily stands out among the rest was how to write algorithms that would modify an image without using any image modification function  within r as such function require an image of class im; however, all of the images that run using the model are of class python.builtin.object.

\subsection{Design and Development of Sub-algorithms}
A total of 7 Sub-Algorithms were developed for this project. The group decided to take up more work if any members finished an algorithm before the others. This provided the group with flexibility if one or more algorithms were unable to be completed due to the nature of their complexity or any sort of conflict. The following sections detail the sub-algorithms that were implemented into the main algorithm. The code associated with each section is as the sub-algorithm appears in the main. Each sub-algorithm has an associated repository on GitHub with additional code that allows it to run and feed images into the classifier. 

\% Talya: I think we should get rid of either intro or this pre-paragraph and describe challenges for each algorithm separately

\subsubsection{Sub-algorithm 1 : RGB Attack}
This algorithm performs image modification by picking random pixels within the image and changing their colors. This is achieved by generating random pixel indices and color changing functions are then applied to it through a loop that runs for each of the selected pixels to generate a unique random color through color channels r, g, b. The amount of selected random pixels is identified by the given budget.\newline
\noindent 
\newline
\noindent R code for RGB Attack Sub-Algorithm:\begin{lstlisting}[language=R, frame=single]
##ALGORITHM 1 Talya___________________________________________________________
  # Generate random pixel indices
  pixel_indices_1 <- sample(pixel_num, budget_alg1, replace = FALSE)
  
  # Change the color of random pixels
  for (j in pixel_indices_1) {
    row_index <- ceiling(j / 224)
    col_index <- j %% 224
    if (col_index == 0){ col_index <- 224}
    
    # Generate new color values
    r <- runif(1, 0, 1)
    g <- runif(1, 0, 1)
    b <- runif(1, 0, 1)
    
    # Change the color of the pixel
    test_array[1, row_index, col_index, ] <- c(r, g, b)
\end{lstlisting}
\subsubsection{Sub-algorithm 2: Pixle algorithm}


This algorithm was based on Pixle algorithm although it has been modified for the outlines of this project.
The Pixle algorithm is a method of adaptive pixel sampling for image processing tasks, presented in the article "Pixel Permutation is a powerful "black box" attack for RGB and infrared deep learning models" (Pomponi et al., 2023).\newline

\noindent The algorithm consists of several iterations. At each iteration, the algorithm randomly selects a set of image pixels and uses them to calculate the error functional. Then the algorithm adaptively updates the pixel weights and repeats the process of sampling and calculating the error in the next iteration.\newline

\noindent The algorithm also contains a parameters that allows you to control the selection of pixels: "budget\_alg", which determines the number of pixels selected at each iteration.\newline
%%

\noindent First, it selects random pixel indeces from "test\_array" and stores them in the variable "pixel\_indices\_2". The number of selected indexes is determined by the variable "budget\_alg2", and the selected indexes will not be repeated.The algorithm then randomly rearranges the selected pixels into "test\_array". \newline 

\noindent To do this, the program uses the "sample" function, which takes the selected pixels from "test\_array" by their indexes and shuffles them using another array, which is created from "test\_array" without the selected pixels. The number of elements to be selected from the second array is also determined by the variable "budget\_alg2". As a result, after the execution of the program, the "test\_array" array will contain the same pixels as before the execution of the program, but they will be arranged in random order, while the selected pixel indexes may change.\newline

\noindent R code for Pixle Sub-Algorithm:
\begin{lstlisting}[language=R, frame=single]
 ##Random Pixel Swap Algorithm: Nicholas and Andrew____________________________
  #Generate random pixel indices
  pixel_indices_2 <- sample(pixel_num, budget_algPIXEL, replace = FALSE)
  
  #Swap Random Pixels
  test_array[pixel_indices_2] <- sample(test_array[setdiff(seq_along(test_array), pixel_indices_2)], budget_algPIXEL)
  
\end{lstlisting}
\subsubsection{Sub-algorithm 3: Adversarial Patch}

Our third algorithm is built upon the neural network's "fooling" technique, referred to as an Adversarial patch. This approach functions by incorporating a path, sticker, or image into an existing visual, rather than modifying it entirely (Zuppichini, 2018). In our implementation, we introduce a "noise" image that comprises randomly colored pixels. This image is highly transparent, with only one percent opacity, and is iteratively superimposed on top of all grass and dandelion images prior to their evaluation through the classifier.\newline

\noindent To provide further insight into the workings of our algorithm, the process begins by utilizing a 99 percent transparent PNG file named "NOISE.png." This file is then resized to match the dimensions of the grass or dandelion image being analyzed. Subsequently, the image is overlaid on top of the target image in a loop with an assigned budget allocated to modify only a small percentage of the original image's pixels before classification. Remarkably, this sub-algorithm of our parent algorithm appears to consistently outwit the classification process when it comes to identifying dandelion images. \newline
%%
\noindent R code for Adversarial Patch Sub-Algorithm :
\begin{lstlisting}[language=R, frame=single]
##FUNCTION 3
apply_algorithm2 <- function(img_path) {
  img <- readPNG("NOISE.png")
  img <- img[,,1:3]
  img[] <- runif(prod(dim(img)))
  alpha <- array(0.99, dim(img)[1:2]) 
  alpha_flat <- as.vector(alpha)
  alpha_flat[1:budget_algAP] <- 1
  img_with_alpha <- abind(array(img_path[1:budget_algAP], dim=c(sqrt(budget_algAP), sqrt(budget_algAP), 3)), array(alpha_flat[1:budget_algAP], dim=c(sqrt(budget_algAP), sqrt(budget_algAP))), along = 3)
  img <- rasterGrob(img, interpolate=TRUE)
  return(img)
}

##Adversarial Patch Algorithm: Mo_____________________________________________
  #Calls Function 3 to Apply Algorithm
  img_mod <- apply_algorithm2(test_array)
  \end{lstlisting}
\subsubsection{Sub-algorithm 4: RGB Channel Smoothing}
The purpose of this algorithm is to smooth randomly selected parts of a given image. This is achieved by adding noise to the pixel. Since the noise is dependent upon the surrounding pixels, these are taken to consideration in the function.
\newline
A breakdown of grass and dandelion images showed that the green and blue channels carry a heavier weight from image to image. Though this is not true for every image, it is true for most. The sub-algorithm takes advantage of this shared aspect and reserves more of it’s allotted budget to alter pixels in the green and blue channels more than that in the red channel. This achieves the goal of fooling a maximum amount of images.
\newline 
\newline
\noindent R code for RGB Channel Smoothing Sub-Algorithm:
\begin{lstlisting}[language=R, frame=single]
##RGB Channel Smoothing Algorithm: Andrew_____________________________________
  #Generate random pixel indices
  pixel_indices_4 <- sample(pixel_num, budget_algSMOOTH, replace = FALSE)
  
  #Add random noise to the pixel values and their RGB channels
  for (j in pixel_indices_4) {
    row_index <- ceiling(j / 224)
    col_index <- j %% 224
    if (col_index == 0){ col_index <- 224}
    
    #Alter red channel the least, these images do not have many values in the red channel
    r_chan <- runif(1, -0.01, 0.01) 
    test_array[1, row_index, col_index, 1] <- test_array[1, row_index, col_index, 1] + r_chan
    
    #Alter green channel is a heavier component of these images
    g_chan <- runif(1, -0.8, 0.8) 
    test_array[1, row_index, col_index, 2] <- test_array[1, row_index, col_index, 2] + g_chan
    
    #Alter blue channel as it is a heavier component of these images
    b_chan <- runif(1, -0.8, 0.8) 
    test_array[1, row_index, col_index, 3] <- test_array[1, row_index, col_index, 3] + b_chan
  }

\end{lstlisting}
\newpage
\subsubsection{Sub-algorithm 5: CCP attack}
R code for Sub-Algorithm 5:
\begin{lstlisting}[language=R, frame=single]
 #FUNCTION 1
change_brightness <- function(img, alpha, beta) {
  new_image <- img
  for (k in pixel_indices_5) {
    row_index <- ceiling(k / 224)
    col_index <- k %% 224
    if (col_index == 0){ col_index <- 224}
    new_image[, row_index, col_index ,] <- pmax(pmin(alpha*new_image[, row_index, col_index ,] + beta, 255), 0)
  } 
  return(new_image)
}

##FUNCTION 2
ccp_attack <- function(x, trans) {
  img <- x
  for (channel in seq_len(dim(x)[3])) {
    for (j in pixel_indices_5) {
      row_index <- ceiling(j / 224)
      col_index <- j %% 224
      if (col_index == 0){ col_index <- 224}
      r <- img[,row_index,col_index,1]
      g <- img[,row_index,col_index,2]
      b <- img[,row_index,col_index,3]
      temp <- r * trans[1, channel] + g * trans[2, channel] + b * trans[3, channel]
      img[, row_index, col_index , channel] <- temp/3
      img1 = change_brightness(img, 1, 30)
    }
    return(img1)
  }
}
 
   ##CCP Attack Algorithm: Hershi________________________________________________
  #Generate random pixel indices
  pixel_indices_5 <-sample(pixel_num, budget_algCCP, replace = FALSE)
  a <- runif(3, 0, 1)
  b <- runif(3, 0, 1)
  c <- runif(3, 0, 1)
  trans <- array(c(a, b, c), dim = c(3, 3))
  
  
  test_array <- ccp_attack(test_array, trans)

  \end{lstlisting}\newpage

\subsection{Design and Development of Main Algorithm}
The code provided below does not include the individual sub-algorithms as those are to be referenced in sections 2.2.1-5. The placement of these sub-algorithms and their associated functions are marked by a double-hash "\#\#" comment followed by a note.

R code for the Main Algorithm:
\begin{lstlisting}[language=R, frame=single]
#MAIN ALGORITHM CONSISTING OF 5 SUB-ALGORITHMS
#Each Sub-Algorithm Was Assigned a Weight Determined by 
#Its Amount of Convinced Images from the Test Set

#REQUIRED LIBRARIES
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
library(jpeg)
library(png)
library(abind)
library(grid)

setwd("~/Desktop/Project")
model_list <- load_model_tf("./dandelion_model/")
model <- model_list

##FUNCTIONS FOR SUB-ALGORITHMS IN SECTIONS 2.2.1-5 ARE PLACED HERE

#Set target image size
target_size <- c(224, 224)

#Create Data Frame
res <- data.frame(file = character(), class = character(), percent_dandelion = numeric(), percent_dandelions = numeric(), stringsAsFactors = FALSE)

#Begin Grass Files##############################################################

f <- list.files("./grass")
for (i in f) {
  
  #Load image as Keras tensor object
  test_image <- image_load(paste("./grass/", i, sep = ""), target_size = target_size)
  
  #Convert Keras tensor object to  array
  test_array <- image_to_array(test_image)
  
  #Assign Budgets
  test_array <- array_reshape(test_array, c(1, dim(test_array)))
  test_array <- test_array / 255
  pixel_num <- 224 * 224
  budget <- round(pixel_num * 0.01 * 0.009)
  
  budget_algPIXEL<- budget*(0.01059) #Weight Decided for Pixel Swap Algorithm 
  budget_algSMOOTH<- budget*(0.08669) #Weight Decided for Channel Smoothing Algorithm 
  budget_algRGB<- budget*(0.09719) #Weight Decided for RGB attack Algorithm 
  budget_algAP<- budget*(0.40257)  #Weight Decided for Adversarial Patch Algorithm 
  budget_algCCP<- budget*(0.40257) #Weight Decided for CCP attack Algorithm

  ##ALGORITHMS ARE PLACED HERE IN THE ORDER THAT THEY APPEAR IN SECTIONS 2.1.1-5

  pred <- model %>% predict(test_array)
  
  #Record results in Res
  if (pred[1,2] < 0.50){
    res <- rbind(res, data.frame(file = i, class = "not_grass", percent_dandelion = pred[1,1], percent_grass = 1- pred[1,1]))
  } else {
    res <- rbind(res, data.frame(file = i, class = "grass", percent_dandelion = pred[1,1], percent_grass = 1 - pred[1,1]))
  }
}

#Begin Dandelion Files##########################################################

f <- list.files("./dandelions")
for (i in f) {
  
  #Load image as Keras tensor object
  test_image <- image_load(paste("./dandelions/", i, sep = ""), target_size = target_size)
  
  #Convert Keras tensor object to  array
  test_array <- image_to_array(test_image)
  
  #Assign Budgets
  test_array <- array_reshape(test_array, c(1, dim(test_array)))
  test_array <- test_array / 255
  pixel_num <- 224 * 224
  budget <- round(pixel_num * 0.01 * 0.009)
  
  budget_algPIXEL<- budget*(0.01059) #Weight Decided for Pixel Swap Algorithm 
  budget_algSMOOTH<- budget*(0.08669) #Weight Decided for Channel Smoothing Algorithm 
  budget_algRGB<- budget*(0.09719) #Weight Decided for RGB attack Algorithm 
  budget_algAP<- budget*(0.40257)  #Weight Decided for Adversarial Patch Algorithm 
  budget_algCCP<- budget*(0.40257) #Weight Decided for CCP attack Algorithm

 ##ALGORITHMS ARE PLACED HERE IN THE ORDER THAT THEY APPEAR IN SECTIONS 2.1.1-5

 pred <- model %>% predict(test_array)
  
  #Record results in Res
  if (pred[1,1] < 0.50){
    res <- rbind(res, data.frame(file = i, class = "not_dandelion", percent_dandelion = pred[1,1], percent_grass = 1- pred[1,1]))
  } else {
    res <- rbind(res, data.frame(file = i, class = "dandelion", percent_dandelion = pred[1,1], percent_grass = 1 - pred[1,1]))
  }
}

print(res)
View(res)  \end{lstlisting}
\subsubsection{How to Use the Main Algorithm}
The zipped submission folder includes two folders labeled "grass" and "dandelions". They currently contain exclusively the images provided to the group. The main algorithm will then be loaded into R-Studio and a proper working directory shall be set to the submission folder. Running the main algorithm at this point will classify all images contained in both folders with output displayed in the R-Studio Console. If the user desires to use different images, they shall be placed in the respective folders. 
\subsubsection{The Main Classifier}
A large component of the Main Algorithm is comprised of the looping structure of the classifier model. This looping structure ensures that all images in the grass and dandelion folders can be classified at once.  Altering the code in this manner allowed the group to analyze output at a higher rate and re-scale input as desired. The output for all images in the grass folder will read "grass" or "not\_grass", the dandelions folder: "dandelion" or "not\_dandelion". Additionally, the percent confidence of grass and dandelion will also be printed for each input.
\newline
R code for the Classifier Algorithm:
\begin{lstlisting}[language=R, frame=single]
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)

setwd("/Users/mohamedabuelreish")

model_list <- load_model_tf("./dandelion_model")
model <- model_list

target_size <- c(224, 224)
res <- data.frame(file = character(), class = character(), percent_dandelion = numeric(), percent_grass = numeric(), stringsAsFactors = FALSE)

f <- list.files("./grass")
for (i in f){
  test_image <- image_load(paste("./grass/",i,sep=""),
                           target_size = target_size)
  x <- image_to_array(test_image)
  x <- array_reshape(x, c(1, dim(x)))
  x <- x/255
  pred <- model %>% predict(x)
  if (pred[1,2] < 0.50){
    res <- rbind(res, data.frame(file = i, class = "not_grass", percent_dandelion = pred[1,1], percent_grass = 1- pred[1,1]))
  } else {
    res <- rbind(res, data.frame(file = i, class = "grass", percent_dandelion = pred[1,1], percent_grass = 1 - pred[1,1]))
  }
}

f <- list.files("./dandelions")
for (i in f){
  test_image <- image_load(paste("./dandelions/",i,sep=""),
                           target_size = target_size)
  x <- image_to_array(test_image)
  x <- array_reshape(x, c(1, dim(x)))
  x <- x/255
  pred <- model %>% predict(x)
  if (pred[1,1] < 0.50){
    res <- rbind(res, data.frame(file = i, class = "not_dandelion", percent_dandelion = pred[1,1], percent_grass = 1 - pred[1,1]))
  } else {
    res <- rbind(res, data.frame(file = i, class = "dandelion", percent_dandelion = pred[1,1], percent_grass = 1 - pred[1,1]))
  }
}

print(res)

\end{lstlisting}
\newline 
The above code initializes the language model and sets a predetermined size for the images to be analyzed. Subsequently, the image resizing process is performed, and the standard prediction model is executed. The "res" variable is then adapted to present the algorithm's predictions for a particular image, including the percentage confidence associated with each class. Specifically, for images contained within the "grass" directory, the algorithm determines the presence or absence of grass within the image. Similarly, for images located in the "dandelion" directory, the algorithm predicts whether or not the image contains dandelions.

\subsubsection{Deciding the Weights of each Sub Algorithm}
Deciding the weights of all sub-algorithms is important to improving the ability of algorithm to trick the classifier model.
To decide the weights of each of the five sub-algorithms a looping structure was designed. This loop’s purpose is to gather the average amount of images each sub-algorithm can fool the model with. 
\newline
\newline
R code for the looping structure:
\begin{lstlisting}[language=R, frame=single]
count_grass <- 0
count_dandelion <- 0
for(i in 1:100){

#SUB-ALGORITHM GOES HERE

count_iteration_grass <- sum(res$class == "not_grass")
count_grass <- count_grass + count_iteration_grass

count_iteration_dandelion <- sum(res$class == "not_dandelion")
count_dandelion <- count_dandelion + count_iteration_dandelion

}
count_grass<- count_grass/100
count_dandelion<- count_dandelion/100
print(count_grass)
print(count_dandelion)
\end{lstlisting}
This loop runs a given sub-algorithm 100 times, collecting data on the amount of grass and dandelion images fooled on each iteration. An average is then produced for grass and dandelion images fooled for the given sub-algorithm. The weights are computed like so:
\begin{center}
$W_n=i_n/(\sum_{i=1}^{n} i)$
\end{center}
Where $W_n$ is the weight of the algorithm $n$ and $i_n$ is the amount of images from the provided test set an algorithm $n$ successfully fooled.
\newline
\newline
This method of determining weights enables sub-algorithms that perform well on their own receive a “fair share” of the 1\% pixel change budget allotted for images that are being changed. In the case of the CCP Attack Sub-Algorithm, which was capable of fooling the dandelion classifier with a budget of only 3 pixels, a large weight was awarded. This sub-algorithm offered significantly more performance than the others, perhaps by the nature if it’s design implementing two newly written functions. 
Insert text describing the design of our main algorithm and code as well. 

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Algorithm Name & Grass Images Fooled & Dandelion Images Fooled & Weight Awarded \\
\hline
RGB Attack & 0.00 & 9.17 & 9.719\%\\
\hline
Pixle & 0.00 & 1.00 & 1.059\% \\
\hline
Adversarial Patch & 0.00 & 38.00 & 40.257\% \\
\hline
RGB Channel Smoothing & 0.00 & 8.18 & 8.669\% \\
\hline
CCP Attack & 0.00 & 38.00 & 40.257\% \\
\hline
\end{tabular}
\caption{Algorithm Weight Table}
\label{tab:example}
\end{table}

Note: A further modification that affected the weights is discussed in section 4.3 Performance.
%DO NOT MENTION Testing/Correctness/Verification, run time Complexity and Wall-time, or Complexity. These will be discussed later
%YOU SHOULD MENTION ANY CHALLENGES THAT WERE FACED DURING DEVELOPMENT.
\newpage

\fancyhead[L]{\textbf{Conclusion}}
\section{Conclusion}

In conclusion, the combined effort of all 5 algorithms produces successful deception of all dandelion images. However, it was unable to fool any grass image. All algorithms except one only 

\newpage
\fancyhead[L]{\textbf{Appendix}}
\section{Appendix}
\subsection{Testing/Correctness/Verification}
\subsubsection{Introduction}
Proving the correctness of an algorithm is a very important process in software development. Firstly, it helps to find and correct errors in the algorithm that can lead to unpredictable results in the program. Secondly, the mathematical proof gives confidence to users and other developers in the correctness of the algorithm. This is especially important when working with critical systems, where incorrect execution of the algorithm can lead to serious consequences. In addition, the process of proving the correctness of the algorithm improves problem solving and abstract thinking skills, which can help in the development of more efficient algorithms in the future.\newline

\subsubsection{Loop correctness analysis}
\noindent In this section we are going to prove correctness of code snippets for every loop in this code. The correctness evaluation are going to be performed by the appearing order in the main code.\newline

\noindent \textbf{Change Brightness function}

\begin{lstlisting}[language=R, frame=single]
#Functions Created for Sub-Algorithms
change_brightness <- function(img, alpha, beta) {
  new_image <- img
  for (k in pixel_indices_5) {
    row_index <- ceiling(k / 224)
    col_index <- k %% 224
    if (col_index == 0){ col_index <- 224}
    new_image[, row_index, col_index ,] <- pmax(pmin(alpha*new_image[, row_index, col_index ,] + beta, 255), 0)
  } 
  return(new_image)
}
\end{lstlisting}
 For the function above which belongs to sub-algorithm 4, CCP attack, each time the loop iterates, new\_image includes a duplicate of the original image matrix img with the brightness of the pixels identified by pixel\_indices\_5 altered in accordance with the alpha and beta values at the time. The brightness of the pixel at row index ceiling(k/224) and column index k\%\% 224 (or 224 if k is a multiple of 224) is specifically scaled by alpha and shifted by beta for each k in pixel\_indices\_5, and the resulting value is clamped to the range of 0 to 255.\newline

\noindent Because the function makes a copy of the original image matrix at the beginning of the function and because the loop only changes the brightness of the pixels provided in pixel\_indices\_5, it can be firmly stated that this loop invariant initializes correctly. The adjusted pixel values are clamped to the legal range of 0 to 255 due to the pmax and pmin functions. Furthermore, since alpha and beta are not changed during the loop, their values remain unchanged throughout all of the loop iterations. With each loop iteration, the loop invariant is preserved, and at the end of the loop, when k reaches pixel\_indices\_5, new\_image includes an updated image matrix with the brightness of the specified pixels adjusted by the provided scaling and shifting factors, making the loop invariant true upon loop termination.\newline
\newpage
\noindent \textbf{CCP Attack Function}
\begin{lstlisting}[language=R, frame=single]
ccp_attack <- function(x, trans) {
  img <- x
  for (channel in seq_len(dim(x)[3])) {
    for (j in pixel_indices_5) {
      row_index <- ceiling(j / 224)
      col_index <- j %% 224
      if (col_index == 0){ col_index <- 224}
      r <- img[,row_index,col_index,1]
      g <- img[,row_index,col_index,2]
      b <- img[,row_index,col_index,3]
      temp <- r * trans[1, channel] + g * trans[2, channel] + b * trans[3, channel]
      img[, row_index, col_index , channel] <- temp/3
      img1 = change_brightness(img, 1, 30)
    }
        
    return(img1)
  }
}
\end{lstlisting}

\noindent For ccp\_attack function in section 2.2.5 there is no evident mathematical property that holds true across each iteration of the nested loop since pixel\_indices\_5 is a vector of random indices. However, there are a few pertinent facts that we can point out that might be useful in determining whether the loop is correct:\newline

\noindent 1. In pixel\_indices\_5, each pixel is changed precisely once per channel.\newline
\noindent 2. All pixels and channels use the same transformation matrix, trans.\newline
\noindent 3. The sequence in which the pixels are updated has no effect on the calculations carried out inside the loop.\newline
\noindent 4.These details allow us to pinpoint the potential loop invariant that follows:\newline

\noindent The output image img begins each iteration of the nested loop with the same pixel values as the input image x for any pixels that have not yet been processed updated for the channel at hand.\newline

\noindent As long as the calculations inside the loop are accurate and do not change any pixels outside of pixel\_indices\_5, this loop invariant ought to be true throughout each iteration of the nested loop.\newline
\subsubsection{Proving correctness of image load and predictions}

To be able to test any algorithm created throughout this project we would be able to tell the results of classification with assigned probabilities.  To achieve that we have added
\begin{lstlisting}[language=R, frame=single]
    if ( pred [1 ,2] < 0.50) {
res <- rbind ( res , data . frame ( file = i , class = " not _ grass " ) )
} else {
res <- rbind ( res , data . frame ( file = i , class = " grass " ) )
}
\end{lstlisting}
instead of lines
\begin{lstlisting}[language=R, frame=single]
    if(pred[1,2]<0.50){
 print(i)
\end{lstlisting}
\newpage
Thus, we have received this output (Note, the tables below have rounded the number to  3 digits. The actual output is rounded to 9 digits):
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
image # & Class & Percent Dandelion & Percent Grass\\
\hline
1 & grass & 0.040 & 0.960\\
\hline
2 & grass & 0.002& 0.997\\
\hline
3& grass& 0.002&0.998\\
\hline
4& grass & 0.014&0.985\\
\hline
5 & grass & 0.003 &0.997\\
\hline
\end{tabular}
\caption{Original model output for grass.
First 5 outputs}
\label{tab:example}
\end{table}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
image # & Class & Percent Dandelion & Percent Grass\\
\hline
51 & dandelion & 0.713 & 0.287\\
\hline
52 & dandelion & 0.949 & 0.051\\
\hline
53& dandelion& 0.513 & 0.487\\
\hline
54& dandelion & 0.860 & 0.140\\
\hline
55 & dandelion & 0.956 & 0.044\\
\hline
\end{tabular}
\caption{Original model output for dandelion.
First 5 outputs}
\label{tab:example}
\end{table}

Although, we cannot test the model itself, the given output let's us arrive to the conclusion that image loading, transforming image to array, reshaping image array as well as model prediction works correctly and as expected.

\subsubsection{Further Testing}
A compilation of dandelion and grass images were selected from google to further verify the main algorithm's ability to fool the classifier. These images are different than the provided images. They are held in folders named "grass\_test\_online" and "dandelions\_test\_online" which are included in the submission zip folder for Project 2. Each Sub-Algorithm was tested with these images in a similar manner to how the weightswere determined in section 2.3.2. The results reaffirmed that these Sub-Algorithms can fool the classifier.
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
Algorithm Name & Grass Images Fooled & Dandelion Images Fooled(out of 50)\\
\hline
RGB Attack & 0.00 & 18.50\\
\hline
Pixle & 0.00 & 13.00\\
\hline
Adversarial Patch & 0.00 & 50.00\\
\hline
RGB Channel Smoothing & 0.00 & 20.00\\
\hline
CCP Attack & 0.00 & 50.00\\
\hline
\end{tabular}
\caption{Algorithm Further Testing Results Table}
\label{tab:example}
\end{table}

\newpage
\subsection{Runtime Complexity and Walltime}
\subsubsection{Introduction}
Time complexity is defined as the amount of time taken by an algorithm to run, as a function of the length of the input. It measures the time taken to execute each statement of code in an algorithm. Wall-time on the other hand, is simply the time it takes for the program to run. Unlike wall-time, time complexity does not examine the total execution time of an algorithm, but instead provides useful information about the change in an algorithm’s execution time as the number of operations changes. Analyzing the time complexity of an algorithm can thus define the effectiveness of an algorithm, especially since there are several different ways of solving a problem. Being mindful of the time complexity of our algorithm makes us efficient programmers.\newline
\subsubsection{Runtime Complexity Analysis}


\newpage
\subsection{Performance}
After the application of these weights, the outputs we received saw an increased confidence from the classifier. The teams main algorithm was convincing the classifier that images of dandelions had a confidence rate in the $10e-20$ range of magnitude that they were dandelions. This observation convinced the group to reduce the overall budget of 1\% to an amount much smaller. The overall 1\% budget was multiplied by 0.009 and consequentially the weights. This lowered the level of confidence, but within the realm that all dandelion images could still convinced. In simplest terms, the main algorithm operating with 1\% budget was excessive for the needs of fooling the classifier.
\newline
\newline
\indent Since the alteration made here reduces the amount of pixels that are to be changed, the performance score $\sum_{b=1}^{0.01*P} f*(P/b)$ of the main algorithm increases. This trade off was made as the algorithm consistently fools the same amount of images with a fraction of the allowed budget as seen in figure 1.
\newline

\begin{figure}[htbp]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Performance.jpg}
    \caption{Performance with 1\% Budget}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Performance2.jpg}
    \caption{Performance with 0.009 Multiplier}
  \end{minipage}
\end{figure}
\noindent Note: the columns from left to right in these figures are Image Number, Dandelion Classification, Percent Dandelion, and Percent Grass.
\newpage

\fancyhead[L]{\textbf{References}}
\section{References}
\begin{enumerate}
    \item Pomponi, J., Dantoni, D., Alessandro, N., & Scardapane, S. (2023). Rearranging Pixels is a Powerful Black-Box Attack for RGB and Infrared Deep Learning Models. IEEE Access, 11, 11298–11306. \url{https://doi.org/10.1109/access.2023.3241360}

    \item Zuppichini, Francesco. “Let's Fool a Neural Network!” Medium, Towards Data Science, 14 Mar. 2018,   \url{https://towardsdatascience.com/lets-fool-a-neural-network-b1cded8c4c07}
‌
‌

\end{enumerate}

\end{document}
